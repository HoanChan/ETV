{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de0715fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VITABSET_TRAIN_IMAGE_ROOT = \"F:/data/vitabset/train\"\n",
      "VITABSET_TRAIN_JSON = \"F:/data/vitabset/train.bz2\"\n",
      "VITABSET_VAL_IMAGE_ROOT = \"F:/data/vitabset/val\"\n",
      "VITABSET_VAL_JSON = \"F:/data/vitabset/val.bz2\"\n",
      "VITABSET_TEST_IMAGE_ROOT = \"F:/data/vitabset/test\"\n",
      "VITABSET_TEST_JSON = \"F:/data/vitabset/test.bz2\"\n",
      "STRUCTURE_VOCAB_FILE = \"d:/BIG Projects/Python/ETV/src/data/structure_vocab.txt\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "import config as cf\n",
    "rl = lambda x: x.replace('\\\\', '/')\n",
    "print(f'VITABSET_TRAIN_IMAGE_ROOT = \"{rl(cf.VITABSET_TRAIN_IMAGE_ROOT)}\"')\n",
    "print(f'VITABSET_TRAIN_JSON = \"{rl(cf.VITABSET_TRAIN_JSON)}\"')\n",
    "print(f'VITABSET_VAL_IMAGE_ROOT = \"{rl(cf.VITABSET_VAL_IMAGE_ROOT)}\"')\n",
    "print(f'VITABSET_VAL_JSON = \"{rl(cf.VITABSET_VAL_JSON)}\"')\n",
    "print(f'VITABSET_TEST_IMAGE_ROOT = \"{rl(cf.VITABSET_TEST_IMAGE_ROOT)}\"')\n",
    "print(f'VITABSET_TEST_JSON = \"{rl(cf.VITABSET_TEST_JSON)}\"')\n",
    "print(f'STRUCTURE_VOCAB_FILE = \"{rl(cf.STRUCTURE_VOCAB_FILE)}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5758af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAD = 97\n",
      "STRUCTURE_VOCAB_FILE = 'd:/BIG Projects/Python/ETV/src/data/structure_vocab.txt'\n",
      "VITABSET_TEST_IMAGE_ROOT = 'F:/data/vitabset/test'\n",
      "VITABSET_TEST_JSON = 'F:/data/vitabset/test.bz2'\n",
      "VITABSET_TRAIN_IMAGE_ROOT = 'F:/data/vitabset/train'\n",
      "VITABSET_TRAIN_JSON = 'F:/data/vitabset/train.bz2'\n",
      "VITABSET_VAL_IMAGE_ROOT = 'F:/data/vitabset/val'\n",
      "VITABSET_VAL_JSON = 'F:/data/vitabset/val.bz2'\n",
      "alphabet_len = 94\n",
      "custom_imports = dict(\n",
      "    allow_failed_imports=False,\n",
      "    imports=[\n",
      "        'datasets.table_dataset',\n",
      "        'datasets.transforms.pack_inputs',\n",
      "        'datasets.transforms.table_pad',\n",
      "        'datasets.transforms.table_resize',\n",
      "        'models.backbones.resnet_extra',\n",
      "        'models.backbones.table_resnet_extra',\n",
      "        'models.decoders.table_master_concat_decoder',\n",
      "        'models.dictionaries.table_master_dictionary',\n",
      "        'models.encoders.positional_encoding',\n",
      "        'models.losses.master_tf_loss',\n",
      "        'models.losses.table_l1_loss',\n",
      "        'models.losses.table_loss',\n",
      "        'models.metrics.teds_metric',\n",
      "        'models.postprocessors.table_structure_postprocessor',\n",
      "        'models.recognizer.table_master',\n",
      "        'optimizer.ranger',\n",
      "    ])\n",
      "data_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        max_structure_token_len=600,\n",
      "        type='LoadTokens',\n",
      "        with_cell=False,\n",
      "        with_structure=True),\n",
      "    dict(keep_ratio=True, long_size=480, type='TableResize'),\n",
      "    dict(pad_val=0, size=(\n",
      "        480,\n",
      "        480,\n",
      "    ), type='TablePad'),\n",
      "    dict(\n",
      "        keys=[\n",
      "            'img',\n",
      "        ],\n",
      "        mean=[\n",
      "            0.5,\n",
      "            0.5,\n",
      "            0.5,\n",
      "        ],\n",
      "        meta_keys=(\n",
      "            'filename',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "            'img_norm_cfg',\n",
      "            'ori_filename',\n",
      "            'pad_shape',\n",
      "            'valid_ratio',\n",
      "        ),\n",
      "        std=[\n",
      "            0.5,\n",
      "            0.5,\n",
      "            0.5,\n",
      "        ],\n",
      "        type='PackInputs'),\n",
      "]\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(_scope_='mmocr', interval=1, type='CheckpointHook'),\n",
      "    logger=dict(_scope_='mmocr', interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(_scope_='mmocr', type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(_scope_='mmocr', type='DistSamplerSeedHook'),\n",
      "    sync_buffer=dict(_scope_='mmocr', type='SyncBuffersHook'),\n",
      "    timer=dict(_scope_='mmocr', type='IterTimerHook'),\n",
      "    visualization=dict(\n",
      "        _scope_='mmocr',\n",
      "        draw_gt=False,\n",
      "        draw_pred=False,\n",
      "        enable=False,\n",
      "        interval=1,\n",
      "        show=False,\n",
      "        type='VisualizationHook'))\n",
      "default_scope = 'mmocr'\n",
      "dictionary = dict(\n",
      "    dict_file='d:/BIG Projects/Python/ETV/src/data/structure_vocab.txt',\n",
      "    same_start_end=True,\n",
      "    type='TableMasterDictionary',\n",
      "    with_end=True,\n",
      "    with_padding=True,\n",
      "    with_start=True,\n",
      "    with_unknown=True)\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(\n",
      "    _scope_='mmocr', by_epoch=True, type='LogProcessor', window_size=10)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        gcb_config=dict(\n",
      "            att_scale=False,\n",
      "            fusion_type='channel_add',\n",
      "            headers=1,\n",
      "            layers=[\n",
      "                False,\n",
      "                True,\n",
      "                True,\n",
      "                True,\n",
      "            ],\n",
      "            ratio=0.0625),\n",
      "        input_dim=3,\n",
      "        layers=[\n",
      "            1,\n",
      "            2,\n",
      "            5,\n",
      "            3,\n",
      "        ],\n",
      "        type='TableResNetExtra'),\n",
      "    data_preprocessor=dict(\n",
      "        mean=[\n",
      "            127.5,\n",
      "            127.5,\n",
      "            127.5,\n",
      "        ],\n",
      "        std=[\n",
      "            127.5,\n",
      "            127.5,\n",
      "            127.5,\n",
      "        ],\n",
      "        type='TextRecogDataPreprocessor'),\n",
      "    decoder=dict(\n",
      "        d_model=512,\n",
      "        decoder=dict(\n",
      "            dropout=0.0,\n",
      "            feed_forward=dict(d_ff=2024, d_model=512, dropout=0.0),\n",
      "            self_attn=dict(d_model=512, dropout=0.0, headers=8),\n",
      "            size=512,\n",
      "            src_attn=dict(d_model=512, dropout=0.0, headers=8)),\n",
      "        dictionary=dict(\n",
      "            dict_file='d:/BIG Projects/Python/ETV/src/data/structure_vocab.txt',\n",
      "            same_start_end=True,\n",
      "            type='TableMasterDictionary',\n",
      "            with_end=True,\n",
      "            with_padding=True,\n",
      "            with_start=True,\n",
      "            with_unknown=True),\n",
      "        max_seq_len=600,\n",
      "        module_loss=dict(\n",
      "            loss_bbox=dict(reduction='sum', type='TableL1Loss'),\n",
      "            loss_token=dict(\n",
      "                ignore_index=97, reduction='mean', type='MASTERTFLoss'),\n",
      "            type='TableLoss'),\n",
      "        n_head=8,\n",
      "        n_layers=3,\n",
      "        postprocessor=dict(type='TableStructurePostprocessor'),\n",
      "        type='TableMasterConcatDecoder'),\n",
      "    encoder=dict(\n",
      "        d_model=512, dropout=0.2, max_len=5000, type='PositionalEncoding'),\n",
      "    type='TABLEMASTER')\n",
      "optim_wrapper = dict(\n",
      "    _scope_='mmocr',\n",
      "    clip_grad=dict(max_norm=35, norm_type=2),\n",
      "    optimizer=dict(lr=0.001, type='Ranger', weight_decay=0.0),\n",
      "    type='AmpOptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=False,\n",
      "        end=50,\n",
      "        start_factor=0.3333333333333333,\n",
      "        type='LinearLR'),\n",
      "    dict(by_epoch=True, gamma=0.1, milestones=[\n",
      "        12,\n",
      "        15,\n",
      "    ], type='MultiStepLR'),\n",
      "]\n",
      "randomness = dict(seed=None)\n",
      "resume = False\n",
      "start_end_same = False\n",
      "test_cfg = dict(_scope_='mmocr', type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file='F:/data/vitabset/test.bz2',\n",
      "        data_prefix=dict(img_path='F:/data/vitabset/test'),\n",
      "        ignore_empty_cells=True,\n",
      "        max_data=-1,\n",
      "        max_structure_len=600,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                max_structure_token_len=600,\n",
      "                type='LoadTokens',\n",
      "                with_cell=False,\n",
      "                with_structure=True),\n",
      "            dict(keep_ratio=True, long_size=480, type='TableResize'),\n",
      "            dict(pad_val=0, size=(\n",
      "                480,\n",
      "                480,\n",
      "            ), type='TablePad'),\n",
      "            dict(\n",
      "                keys=[\n",
      "                    'img',\n",
      "                ],\n",
      "                mean=[\n",
      "                    0.5,\n",
      "                    0.5,\n",
      "                    0.5,\n",
      "                ],\n",
      "                meta_keys=(\n",
      "                    'filename',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                    'img_norm_cfg',\n",
      "                    'ori_filename',\n",
      "                    'pad_shape',\n",
      "                    'valid_ratio',\n",
      "                ),\n",
      "                std=[\n",
      "                    0.5,\n",
      "                    0.5,\n",
      "                    0.5,\n",
      "                ],\n",
      "                type='PackInputs'),\n",
      "        ],\n",
      "        random_sample=False,\n",
      "        split_filter=None,\n",
      "        test_mode=True,\n",
      "        type='PubTabNetDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_dataset = dict(\n",
      "    ann_file='F:/data/vitabset/test.bz2',\n",
      "    data_prefix=dict(img_path='F:/data/vitabset/test'),\n",
      "    ignore_empty_cells=True,\n",
      "    max_data=-1,\n",
      "    max_structure_len=600,\n",
      "    pipeline=[\n",
      "        dict(type='LoadImageFromFile'),\n",
      "        dict(\n",
      "            max_structure_token_len=600,\n",
      "            type='LoadTokens',\n",
      "            with_cell=False,\n",
      "            with_structure=True),\n",
      "        dict(keep_ratio=True, long_size=480, type='TableResize'),\n",
      "        dict(pad_val=0, size=(\n",
      "            480,\n",
      "            480,\n",
      "        ), type='TablePad'),\n",
      "        dict(\n",
      "            keys=[\n",
      "                'img',\n",
      "            ],\n",
      "            mean=[\n",
      "                0.5,\n",
      "                0.5,\n",
      "                0.5,\n",
      "            ],\n",
      "            meta_keys=(\n",
      "                'filename',\n",
      "                'ori_shape',\n",
      "                'img_shape',\n",
      "                'scale_factor',\n",
      "                'img_norm_cfg',\n",
      "                'ori_filename',\n",
      "                'pad_shape',\n",
      "                'valid_ratio',\n",
      "            ),\n",
      "            std=[\n",
      "                0.5,\n",
      "                0.5,\n",
      "                0.5,\n",
      "            ],\n",
      "            type='PackInputs'),\n",
      "    ],\n",
      "    random_sample=False,\n",
      "    split_filter=None,\n",
      "    test_mode=True,\n",
      "    type='PubTabNetDataset')\n",
      "test_evaluator = dict(\n",
      "    _scope_='mmocr',\n",
      "    dataset_prefixes=None,\n",
      "    metrics=[\n",
      "        dict(\n",
      "            collect_device='cpu',\n",
      "            ignore_nodes=None,\n",
      "            prefix=None,\n",
      "            structure_only=True,\n",
      "            type='TEDSMetric'),\n",
      "    ],\n",
      "    type='MultiDatasetsEvaluator')\n",
      "train_cfg = dict(\n",
      "    _scope_='mmocr', max_epochs=17, type='EpochBasedTrainLoop', val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file='F:/data/vitabset/train.bz2',\n",
      "        data_prefix=dict(img_path='F:/data/vitabset/train'),\n",
      "        ignore_empty_cells=True,\n",
      "        max_data=-1,\n",
      "        max_structure_len=600,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                max_structure_token_len=600,\n",
      "                type='LoadTokens',\n",
      "                with_cell=False,\n",
      "                with_structure=True),\n",
      "            dict(keep_ratio=True, long_size=480, type='TableResize'),\n",
      "            dict(pad_val=0, size=(\n",
      "                480,\n",
      "                480,\n",
      "            ), type='TablePad'),\n",
      "            dict(\n",
      "                keys=[\n",
      "                    'img',\n",
      "                ],\n",
      "                mean=[\n",
      "                    0.5,\n",
      "                    0.5,\n",
      "                    0.5,\n",
      "                ],\n",
      "                meta_keys=(\n",
      "                    'filename',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                    'img_norm_cfg',\n",
      "                    'ori_filename',\n",
      "                    'pad_shape',\n",
      "                    'valid_ratio',\n",
      "                ),\n",
      "                std=[\n",
      "                    0.5,\n",
      "                    0.5,\n",
      "                    0.5,\n",
      "                ],\n",
      "                type='PackInputs'),\n",
      "        ],\n",
      "        random_sample=False,\n",
      "        split_filter=None,\n",
      "        test_mode=False,\n",
      "        type='PubTabNetDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "train_dataset = dict(\n",
      "    ann_file='F:/data/vitabset/train.bz2',\n",
      "    data_prefix=dict(img_path='F:/data/vitabset/train'),\n",
      "    ignore_empty_cells=True,\n",
      "    max_data=-1,\n",
      "    max_structure_len=600,\n",
      "    pipeline=[\n",
      "        dict(type='LoadImageFromFile'),\n",
      "        dict(\n",
      "            max_structure_token_len=600,\n",
      "            type='LoadTokens',\n",
      "            with_cell=False,\n",
      "            with_structure=True),\n",
      "        dict(keep_ratio=True, long_size=480, type='TableResize'),\n",
      "        dict(pad_val=0, size=(\n",
      "            480,\n",
      "            480,\n",
      "        ), type='TablePad'),\n",
      "        dict(\n",
      "            keys=[\n",
      "                'img',\n",
      "            ],\n",
      "            mean=[\n",
      "                0.5,\n",
      "                0.5,\n",
      "                0.5,\n",
      "            ],\n",
      "            meta_keys=(\n",
      "                'filename',\n",
      "                'ori_shape',\n",
      "                'img_shape',\n",
      "                'scale_factor',\n",
      "                'img_norm_cfg',\n",
      "                'ori_filename',\n",
      "                'pad_shape',\n",
      "                'valid_ratio',\n",
      "            ),\n",
      "            std=[\n",
      "                0.5,\n",
      "                0.5,\n",
      "                0.5,\n",
      "            ],\n",
      "            type='PackInputs'),\n",
      "    ],\n",
      "    random_sample=False,\n",
      "    split_filter=None,\n",
      "    test_mode=False,\n",
      "    type='PubTabNetDataset')\n",
      "tta_model = dict(_scope_='mmocr', type='EncoderDecoderRecognizerTTAModel')\n",
      "val_cfg = dict(_scope_='mmocr', type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file='F:/data/vitabset/val.bz2',\n",
      "        data_prefix=dict(img_path='F:/data/vitabset/val'),\n",
      "        ignore_empty_cells=True,\n",
      "        max_data=-1,\n",
      "        max_structure_len=600,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                max_structure_token_len=600,\n",
      "                type='LoadTokens',\n",
      "                with_cell=False,\n",
      "                with_structure=True),\n",
      "            dict(keep_ratio=True, long_size=480, type='TableResize'),\n",
      "            dict(pad_val=0, size=(\n",
      "                480,\n",
      "                480,\n",
      "            ), type='TablePad'),\n",
      "            dict(\n",
      "                keys=[\n",
      "                    'img',\n",
      "                ],\n",
      "                mean=[\n",
      "                    0.5,\n",
      "                    0.5,\n",
      "                    0.5,\n",
      "                ],\n",
      "                meta_keys=(\n",
      "                    'filename',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                    'img_norm_cfg',\n",
      "                    'ori_filename',\n",
      "                    'pad_shape',\n",
      "                    'valid_ratio',\n",
      "                ),\n",
      "                std=[\n",
      "                    0.5,\n",
      "                    0.5,\n",
      "                    0.5,\n",
      "                ],\n",
      "                type='PackInputs'),\n",
      "        ],\n",
      "        random_sample=False,\n",
      "        split_filter=None,\n",
      "        test_mode=False,\n",
      "        type='PubTabNetDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=1,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_dataset = dict(\n",
      "    ann_file='F:/data/vitabset/val.bz2',\n",
      "    data_prefix=dict(img_path='F:/data/vitabset/val'),\n",
      "    ignore_empty_cells=True,\n",
      "    max_data=-1,\n",
      "    max_structure_len=600,\n",
      "    pipeline=[\n",
      "        dict(type='LoadImageFromFile'),\n",
      "        dict(\n",
      "            max_structure_token_len=600,\n",
      "            type='LoadTokens',\n",
      "            with_cell=False,\n",
      "            with_structure=True),\n",
      "        dict(keep_ratio=True, long_size=480, type='TableResize'),\n",
      "        dict(pad_val=0, size=(\n",
      "            480,\n",
      "            480,\n",
      "        ), type='TablePad'),\n",
      "        dict(\n",
      "            keys=[\n",
      "                'img',\n",
      "            ],\n",
      "            mean=[\n",
      "                0.5,\n",
      "                0.5,\n",
      "                0.5,\n",
      "            ],\n",
      "            meta_keys=(\n",
      "                'filename',\n",
      "                'ori_shape',\n",
      "                'img_shape',\n",
      "                'scale_factor',\n",
      "                'img_norm_cfg',\n",
      "                'ori_filename',\n",
      "                'pad_shape',\n",
      "                'valid_ratio',\n",
      "            ),\n",
      "            std=[\n",
      "                0.5,\n",
      "                0.5,\n",
      "                0.5,\n",
      "            ],\n",
      "            type='PackInputs'),\n",
      "    ],\n",
      "    random_sample=False,\n",
      "    split_filter=None,\n",
      "    test_mode=False,\n",
      "    type='PubTabNetDataset')\n",
      "val_evaluator = dict(\n",
      "    _scope_='mmocr',\n",
      "    dataset_prefixes=None,\n",
      "    metrics=[\n",
      "        dict(\n",
      "            collect_device='cpu',\n",
      "            ignore_nodes=None,\n",
      "            prefix=None,\n",
      "            structure_only=True,\n",
      "            type='TEDSMetric'),\n",
      "    ],\n",
      "    type='MultiDatasetsEvaluator')\n",
      "vis_backends = [\n",
      "    dict(_scope_='mmocr', type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    _scope_='mmocr',\n",
      "    name='visualizer',\n",
      "    type='TextRecogLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmengine.config import Config\n",
    "\n",
    "# Load config\n",
    "cfg = Config.fromfile('../src/configs/etv_concat_resnetex_ranger.py')\n",
    "print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d12f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.backbones.resnet_extra import ResNetExtra\n",
    "from models.decoders.table_master_concat_decoder import TableMasterConcatDecoder\n",
    "from models.dictionaries.table_master_dictionary import TableMasterDictionary\n",
    "from models.losses.master_tf_loss import MASTERTFLoss\n",
    "from models.metrics.teds_metric import TEDSMetric\n",
    "from models.postprocessors.table_master_postprocessor import TableMasterPostprocessor\n",
    "from datasets.table_dataset import PubTabNetDataset\n",
    "from datasets.transforms.table_resize import TableResize\n",
    "from datasets.transforms.table_pad import TablePad\n",
    "from datasets.transforms.load_tokens import LoadTokens\n",
    "from datasets.transforms.pack_inputs import PackInputs\n",
    "from optimizer.ranger import Ranger\n",
    "from mmocr.utils import register_all_modules\n",
    "register_all_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba36eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmocr.registry import DATASETS\n",
    "dataset_config = cfg.train_dataloader.dataset.copy()\n",
    "dataset_pipeline = dataset_config['pipeline']\n",
    "dataset_config['pipeline'] = []\n",
    "dataset_config['max_data'] = 100\n",
    "# Build dataset\n",
    "dataset = DATASETS.build(dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53c87723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img_path': 'F:/data/vitabset/train\\\\143530.png', 'sample_idx': 1, 'instances': [{'tokens': ['<thead>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '</thead>', '<tbody>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '</tbody>'], 'type': 'structure'}, {'tokens': ['N', 'ộ', 'i', ' ', 'd', 'u', 'n', 'g'], 'cell_id': 0, 'type': 'content', 'bbox': [10, 9, 92, 38]}, {'tokens': ['V', 'à', 'n', 'g'], 'cell_id': 1, 'type': 'content', 'bbox': [196, 9, 247, 38]}, {'tokens': ['B', 'ạ', 'c'], 'cell_id': 2, 'type': 'content', 'bbox': [420, 9, 459, 38]}, {'tokens': ['Đ', 'ồ', 'n', 'g'], 'cell_id': 3, 'type': 'content', 'bbox': [625, 9, 678, 38]}, {'tokens': ['5', 'x', '5', ' ', 'N', 'a', 'm', '<br>', 'c', 'h', 'i', ' ', 't', 'i', 'ế', 't'], 'cell_id': 4, 'type': 'content', 'bbox': [15, 149, 88, 197]}, {'tokens': ['P', 'h', 'i', 'l', 'i', 'p', 'p', 'i', 'n', 'e', 's', '<br>', ' ', 'M', 'a', 's', 'o', 'n', ' ', 'A', 'm', 'o', 's', ' ', '<br>', ' ', 'J', 'u', 's', 't', 'i', 'n', ' ', 'B', 'r', 'o', 'w', 'n', 'l', 'e', 'e', ' ', '<br>', ' ', 'M', 'a', 'r', 'c', 'i', 'o', ' ', 'L', 'a', 's', 's', 'i', 't', 'e', 'r', ' ', '<br>', ' ', 'J', 'e', 'r', 'o', 'm', ' ', 'L', 'a', 's', 't', 'i', 'm', 'o', 's', 'a', ' ', '<br>', ' ', 'C', 'h', 'r', 'i', 's', ' ', 'N', 'e', 'w', 's', 'o', 'm', 'e', ' ', '<br>', ' ', 'C', 'a', 'l', 'v', 'i', 'n', ' ', 'O', 'f', 't', 'a', 'n', 'a', ' ', '<br>', ' ', 'C', 'J', ' ', 'P', 'e', 'r', 'e', 'z', ' ', '<br>', ' ', 'M', 'i', 'c', 'h', 'a', 'e', 'l', ' ', 'P', 'h', 'i', 'l', 'l', 'i', 'p', 's', ' ', '<br>', ' ', 'C', 'h', 'r', 'i', 's', ' ', 'R', 'o'], 'cell_id': 5, 'type': 'content', 'bbox': [126, 45, 317, 302]}, {'tokens': ['C', 'a', 'm', 'p', 'u', 'c', 'h', 'i', 'a', '<br>', 'S', 'o', 'm', 'o', 'e', 'u', 'r', ' ', 'C', 'h', 'a', 'n', 'y', 'v', 'a', 't', 'h', 'a', 'n', 'a', '<br>', 'C', 'h', 'i', 'n', ' ', 'S', 'o', 'p', 'h', 'a', 'n', 'a', '<br>', 'A', 'n', 't', 'h', 'o', 'n', 'y', ' ', 'D', 'o', 'm', 'i', 'n', 'i', 'c', ' ', 'D', 'a', 'r', '<br>', 'D', 'a', 'r', 'r', 'i', 'n', ' ', 'D', 'o', 'r', 's', 'e', 'y', '<br>', 'D', 'a', 'r', 'i', 'u', 's', ' ', 'H', 'e', 'n', 'd', 'e', 'r', 's', 'o', 'n', '<br>', 'J', 'o', 's', 'e', 'p', 'h', ' ', 'H', 'o', 'e', 'u', 'p', '<br>', 'O', 's', 'c', 'a', 'r', ' ', 'L', 'o', 'p', 'e', 's', '<br>', 'D', 'w', 'a', 'y', 'n', 'e', ' ', 'M', 'o', 'r', 'g', 'a', 'n', '<br>', 'P', 'e', 'k', ' ', 'M', 'i', 't', 'h', '<br>', 'B', 'r', 'a', 'n', 'd', 'o', 'n'], 'cell_id': 6, 'type': 'content', 'bbox': [351, 45, 529, 302]}, {'tokens': ['T', 'h', 'á', 'i', ' ', 'L', 'a', 'n', '<br>', 'A', 'n', 't', 'o', 'n', 'i', 'o', ' ', 'P', 'r', 'i', 'c', 'e', ' ', 'S', 'o', 'o', 'n', 't', 'h', 'o', 'r', 'n', 'c', 'h', 'o', 't', 'e', '<br>', 'F', 'r', 'e', 'd', 'e', 'r', 'i', 'c', 'k', ' ', 'L', 'e', 'e', ' ', 'J', 'o', 'n', 'e', 's', ' ', 'L', 'i', 's', 'h', '<br>', 'M', 'o', 's', 'e', 's', ' ', 'M', 'o', 'r', 'g', 'a', 'n', '<br>', 'C', 'h', 'a', 'n', 'a', 't', 'i', 'p', ' ', 'J', 'a', 'k', 'r', 'a', 'w', 'a', 'n', '<br>', 'N', 'a', 't', 't', 'a', 'k', 'a', 'r', 'n', ' ', 'M', 'u', 'a', 'n', 'g', 'b', 'o', 'o', 'n', '<br>', 'N', 'a', 'k', 'o', 'r', 'n', ' ', 'J', 'a', 'i', 's', 'a', 'n', 'u', 'k', '<br>', 'A', 'r', 'n', 'a', 't', ' ', 'P', 'h', 'u', 'a', 'n', 'g', 'l', 'a', '<br>', 'A', 'n', 'a', 's', 'a'], 'cell_id': 7, 'type': 'content', 'bbox': [541, 45, 761, 302]}, {'tokens': ['5', 'x', '5', ' ', 'N', 'ữ', '<br>', 'c', 'h', 'i', ' ', 't', 'i', 'ế', 't'], 'cell_id': 8, 'type': 'content', 'bbox': [21, 413, 82, 461]}, {'tokens': ['I', 'n', 'd', 'o', 'n', 'e', 's', 'i', 'a', '<br>', 'A', 'd', 'e', 'l', 'a', 'i', 'd', 'e', ' ', 'C', 'a', 'l', 'l', 'i', 's', 't', 'a', ' ', 'W', 'o', 'n', 'g', 's', 'o', 'h', 'a', 'r', 'd', 'j', 'o', '<br>', 'A', 'g', 'u', 's', 't', 'i', 'n', ' ', 'E', 'l', 'y', 'a', ' ', 'G', 'r', 'a', 'd', 'i', 't', 'a', ' ', 'R', 'e', 't', 'o', 'n', 'g', '<br>', 'C', 'l', 'a', 'r', 'i', 't', 'a', ' ', 'A', 'n', 't', 'o', 'n', 'i', 'o', '<br>', 'D', 'e', 'w', 'a', ' ', 'A', 'y', 'u', ' ', 'M', 'a', 'd', 'e', ' ', 'S', 'r', 'i', 'a', 'r', 't', 'h', 'a', ' ', 'K', 'u', 's', 'u', 'm', 'a', '<br>', 'D', 'y', 'a', 'h', ' ', 'L', 'e', 's', 't', 'a', 'r', 'i', '<br>', 'H', 'e', 'n', 'n', 'y', ' ', 'S', 'u', 't', 'j', 'i', 'o', 'n', 'o', '<br>', 'K', 'a', 'd', 'e', 'k', ' ', 'P'], 'cell_id': 9, 'type': 'content', 'bbox': [99, 309, 344, 566]}, {'tokens': ['P', 'h', 'i', 'l', 'i', 'p', 'p', 'i', 'n', 'e', 's', '<br>', 'F', 'r', 'a', 'n', 'c', 'e', ' ', 'M', 'a', 'e', ' ', 'C', 'a', 'b', 'i', 'n', 'b', 'i', 'n', '<br>', 'J', 'a', 'n', 'i', 'n', 'e', ' ', 'P', 'o', 'n', 't', 'e', 'j', 'o', 's', '<br>', 'J', 'a', 'c', 'k', ' ', 'A', 'n', 'i', 'm', 'a', 'm', '<br>', 'C', 'l', 'a', 'r', 'e', ' ', 'S', 'a', 'q', 'u', 'i', 'n', 'g', ' ', 'C', 'a', 's', 't', 'r', 'o', '<br>', 'C', 'a', 'm', 'i', 'l', 'l', 'e', ' ', 'C', 'l', 'a', 'r', 'i', 'n', '<br>', 'A', 'n', 'a', ' ', 'K', 'a', 't', 'r', 'i', 'n', 'a', ' ', 'C', 'a', 's', 't', 'i', 'l', 'l', 'o', '<br>', 'A', 'f', 'r', 'i', 'l', ' ', 'B', 'e', 'r', 'n', 'a', 'r', 'd', 'i', 'n', 'o', '<br>', 'E', 'l', 'l', 'a', ' ', 'F', 'a', 'j', 'a', 'r', 'd', 'o', '<br>', 'A', 'n', 'g'], 'cell_id': 10, 'type': 'content', 'bbox': [352, 309, 529, 566]}, {'tokens': ['M', 'a', 'l', 'a', 'y', 's', 'i', 'a', '<br>', 'W', 'e', 'i', ' ', 'Y', 'i', 'n', ' ', 'S', 'a', 'w', '<br>', 'K', 'a', 'l', 'a', 'i', 'm', 'a', 't', 'h', 'i', ' ', 'R', 'a', 'j', 'i', 'n', 't', 'i', 'r', 'a', 'n', '<br>', 'H', 'u', 'i', ' ', 'P', 'i', 'n', ' ', 'P', 'a', 'n', 'g', '<br>', 'Y', 'i', 'n', ' ', 'Y', 'i', 'n', ' ', 'C', 'h', 'o', 'n', 'g', '<br>', 'F', 'o', 'o', 'k', ' ', 'Y', 'e', 'e', ' ', 'Y', 'a', 'p', '<br>', 'S', 'i', 'n', ' ', 'J', 'i', 'e', ' ', 'T', 'a', 'n', '<br>', 'M', 'u', 'n', ' ', 'Y', 'i', ' ', 'C', 'h', 'i', 'a', '<br>', 'P', 'h', 'e', 'i', ' ', 'L', 'i', 'n', 'g', ' ', 'L', 'e', 'e', '<br>', 'P', 'o', 'h', ' ', 'Y', 'e', 'e', ' ', 'O', 'o', 'i', '<br>', 'M', 'a', 'g', 'd', 'e', 'l', 'e', 'n', 'e', ' ', 'L', 'o', 'w', '<br>', 'N', 'u', 'r'], 'cell_id': 11, 'type': 'content', 'bbox': [574, 309, 729, 566]}, {'tokens': ['3', '×', '3', ' ', 'N', 'a', 'm', '<br>', 'c', 'h', 'i', ' ', 't', 'i', 'ế', 't'], 'cell_id': 12, 'type': 'content', 'bbox': [13, 601, 90, 649]}, {'tokens': ['C', 'a', 'm', 'p', 'u', 'c', 'h', 'i', 'a', '<br>', 'D', 'a', 'r', 'r', 'i', 'n', ' ', 'D', 'o', 'r', 's', 'e', 'y', '<br>', 'B', 'r', 'a', 'n', 'd', 'o', 'n', ' ', 'J', 'e', 'r', 'o', 'm', 'e', ' ', 'P', 'e', 't', 'e', 'r', 's', 'o', 'n', '<br>', 'S', 'a', 'y', 'e', 'e', 'd', ' ', 'P', 'r', 'i', 'd', 'g', 'e', 't', 't', '<br>', 'T', 'e', 'p', ' ', 'C', 'h', 'h', 'o', 'r', 'a', 't', 'h'], 'cell_id': 13, 'type': 'content', 'bbox': [126, 573, 317, 678]}, {'tokens': ['P', 'h', 'i', 'l', 'i', 'p', 'p', 'i', 'n', 'e', 's', '<br>', 'A', 'l', 'm', 'o', 'n', 'd', ' ', 'V', 'o', 's', 'o', 't', 'r', 'o', 's', '<br>', 'J', 'o', 's', 'e', 'p', 'h', ' ', 'B', 'a', 'r', 'c', 'o', ' ', 'S', 'e', 'd', 'u', 'r', 'i', 'f', 'a', '<br>', 'J', 'o', 's', 'e', 'p', 'h', ' ', 'E', 'r', 'i', 'o', 'b', 'u', '<br>', 'L', 'e', 'r', 'v', 'i', 'n', ' ', 'Y', 'a', 'm', 'b', 'a', 'o', ' ', 'F', 'l', 'o', 'r', 'e', 's'], 'cell_id': 14, 'type': 'content', 'bbox': [357, 573, 523, 678]}, {'tokens': ['T', 'h', 'á', 'i', ' ', 'L', 'a', 'n', '<br>', 'A', 'n', 't', 'o', 'n', 'i', 'o', ' ', 'P', 'r', 'i', 'c', 'e', ' ', 'S', 'o', 'o', 'n', 't', 'h', 'o', 'r', 'n', 'c', 'h', 'o', 't', 'e', '<br>', 'C', 'h', 'a', 'n', 'a', 't', 'i', 'p', ' ', 'J', 'a', 'k', 'k', 'r', 'a', 'w', 'a', 'n', '<br>', 'F', 'r', 'e', 'd', 'e', 'r', 'i', 'c', 'k', ' ', 'L', 'e', 'e', ' ', 'J', 'o', 'n', 'e', 's', ' ', 'L', 'i', 's', 'h', '<br>', 'M', 'o', 's', 'e', 's', ' ', 'M', 'o', 'r', 'g', 'a', 'n'], 'cell_id': 15, 'type': 'content', 'bbox': [541, 573, 761, 678]}, {'tokens': ['3', '×', '3', ' ', 'N', 'ữ', '<br>', 'c', 'h', 'i', ' ', 't', 'i', 'ế', 't'], 'cell_id': 16, 'type': 'content', 'bbox': [19, 713, 84, 761]}, {'tokens': ['V', 'i', 'ệ', 't', ' ', 'N', 'a', 'm', '<br>', 'T', 'r', 'ư', 'ơ', 'n', 'g', ' ', 'T', 'h', 'ả', 'o', ' ', 'M', 'y', '<br>', 'T', 'r', 'ư', 'ơ', 'n', 'g', ' ', 'T', 'h', 'ả', 'o', ' ', 'V', 'y', '<br>', 'H', 'u', 'ỳ', 'n', 'h', ' ', 'T', 'h', 'ị', ' ', 'N', 'g', 'o', 'a', 'n', '<br>', 'N', 'g', 'u', 'y', 'ễ', 'n', ' ', 'T', 'h', 'ị', ' ', 'T', 'i', 'ể', 'u', ' ', 'D', 'u', 'y'], 'cell_id': 17, 'type': 'content', 'bbox': [142, 685, 301, 790]}, {'tokens': ['P', 'h', 'i', 'l', 'i', 'p', 'p', 'i', 'n', 'e', 's', '<br>', 'A', 'f', 'r', 'i', 'l', ' ', 'B', 'e', 'r', 'n', 'a', 'r', 'd', 'i', 'n', 'o', '<br>', 'J', 'a', 'c', 'k', ' ', 'A', 'n', 'i', 'm', 'a', 'm', '<br>', 'J', 'a', 'n', 'i', 'n', 'e', ' ', 'P', 'o', 'n', 't', 'e', 'j', 'o', 's', '<br>', 'M', 'i', 'k', 'k', 'a', ' ', 'W', 'a', 'm', 'i', 'l', ' ', 'C', 'a', 'c', 'h', 'o'], 'cell_id': 18, 'type': 'content', 'bbox': [367, 685, 513, 790]}, {'tokens': ['I', 'n', 'd', 'o', 'n', 'e', 's', 'i', 'a', '<br>', 'A', 'd', 'e', 'l', 'a', 'i', 'd', 'e', ' ', 'C', 'a', 'l', 'l', 'i', 's', 't', 'a', ' ', 'W', 'o', 'n', 'g', 's', 'o', 'h', 'a', 'r', 'd', 'j', 'o', '<br>', 'A', 'g', 'u', 's', 't', 'i', 'n', ' ', 'E', 'l', 'y', 'a', ' ', 'G', 'r', 'a', 'd', 'i', 't', 'a', ' ', 'R', 'e', 't', 'o', 'n', 'g', '<br>', 'D', 'y', 'a', 'h', ' ', 'L', 'e', 's', 't', 'a', 'r', 'i', '<br>', 'K', 'i', 'm', 'b', 'e', 'r', 'l', 'e', 'y', ' ', 'P', 'i', 'e', 'r', 'r', 'e', '-', 'L', 'o', 'u', 'i', 's'], 'cell_id': 19, 'type': 'content', 'bbox': [536, 685, 767, 790]}], 'img_info': {'height': None, 'width': None, 'split': 'train'}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Kiểm tra 1 sample đầu tiên\n",
    "sample = dataset[1]\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be499a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'LoadImageFromFile'}, {'type': 'LoadTokens', 'with_structure': True, 'with_cell': False, 'max_structure_token_len': 600}, {'type': 'TableResize', 'keep_ratio': True, 'long_size': 480}, {'type': 'TablePad', 'size': (480, 480), 'pad_val': 0}, {'type': 'PackInputs', 'keys': ['img'], 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'meta_keys': ('filename', 'ori_shape', 'img_shape', 'scale_factor', 'img_norm_cfg', 'ori_filename', 'pad_shape', 'valid_ratio')}]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from mmengine.dataset import Compose\n",
    "pipeline = Compose(dataset_pipeline)\n",
    "print(dataset_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e44d07dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  img_path: F:/data/vitabset/train\\143583.png\n",
      "  sample_idx: 51\n",
      "  instances: [\n",
      "  {\n",
      "    tokens: ['<thead>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '</thead>', '<tbody>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '</tbody>']\n",
      "    type: structure\n",
      "  }\n",
      "  {\n",
      "    tokens: ['L', 'ứ', 'a', ' ', 't', 'u', 'ổ', 'i']\n",
      "    cell_id: 0\n",
      "    type: content\n",
      "    bbox: [35, 14, 115, 43]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['D', 'ê', ' ', 'c', 'ỏ']\n",
      "    cell_id: 1\n",
      "    type: content\n",
      "    bbox: [154, 14, 208, 43]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['D', 'ê', ' ', 'B', 'á', 'c', 'h', ' ', 'T', 'h', 'ả', 'o']\n",
      "    cell_id: 2\n",
      "    type: content\n",
      "    bbox: [225, 14, 341, 43]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['D', 'ê', ' ', 'b', 'a', 'r', 'b', 'a', 'r', 'y']\n",
      "    cell_id: 3\n",
      "    type: content\n",
      "    bbox: [349, 14, 447, 43]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['D', 'ê', ' ', 'J', 'u', 'm', 'n', 'a', 'p', 'a', 'r', 'i']\n",
      "    cell_id: 4\n",
      "    type: content\n",
      "    bbox: [454, 14, 570, 43]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['D', 'ê', ' ', 'B', 'e', 'e', 't', 'a', 'l']\n",
      "    cell_id: 5\n",
      "    type: content\n",
      "    bbox: [578, 14, 667, 43]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['S', 'ơ', ' ', 's', 'i', 'n', 'h', ':', ' ', 'Đ', 'ự', 'c']\n",
      "    cell_id: 6\n",
      "    type: content\n",
      "    bbox: [17, 55, 133, 84]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', ',', '2', '9', ' ', 'k', 'g']\n",
      "    cell_id: 7\n",
      "    type: content\n",
      "    bbox: [145, 55, 217, 84]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', ',', '7', '8', ' ', 'k', 'g']\n",
      "    cell_id: 8\n",
      "    type: content\n",
      "    bbox: [247, 55, 319, 84]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', ',', '3', '1', ' ', 'k', 'g']\n",
      "    cell_id: 9\n",
      "    type: content\n",
      "    bbox: [362, 55, 434, 84]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', ',', '4', '1', ' ', 'k', 'g']\n",
      "    cell_id: 10\n",
      "    type: content\n",
      "    bbox: [476, 55, 548, 84]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', ',', '5', ' ', 'k', 'g']\n",
      "    cell_id: 11\n",
      "    type: content\n",
      "    bbox: [591, 55, 654, 84]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['C', 'á', 'i']\n",
      "    cell_id: 12\n",
      "    type: content\n",
      "    bbox: [57, 94, 93, 123]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', ',', '6', '2', ' ', 'k', 'g']\n",
      "    cell_id: 13\n",
      "    type: content\n",
      "    bbox: [145, 94, 217, 123]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', ',', '3', ' ', 'k', 'g']\n",
      "    cell_id: 14\n",
      "    type: content\n",
      "    bbox: [251, 94, 314, 123]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', ',', '1', '9', ' ', 'k', 'g']\n",
      "    cell_id: 15\n",
      "    type: content\n",
      "    bbox: [362, 94, 434, 123]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', ',', '0', ' ', 'k', 'g']\n",
      "    cell_id: 16\n",
      "    type: content\n",
      "    bbox: [481, 94, 544, 123]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', ',', '0', ' ', 'k', 'g']\n",
      "    cell_id: 17\n",
      "    type: content\n",
      "    bbox: [591, 94, 654, 123]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', ' ', 't', 'h', 'á', 'n', 'g', ':', ' ', 'Đ', 'ự', 'c']\n",
      "    cell_id: 18\n",
      "    type: content\n",
      "    bbox: [17, 133, 133, 162]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['6', ',', '1', ' ', 'k', 'g']\n",
      "    cell_id: 19\n",
      "    type: content\n",
      "    bbox: [150, 133, 213, 162]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '1', ',', '6', ' ', 'k', 'g']\n",
      "    cell_id: 20\n",
      "    type: content\n",
      "    bbox: [247, 133, 319, 162]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['9', ',', '4', ' ', 'k', 'g']\n",
      "    cell_id: 21\n",
      "    type: content\n",
      "    bbox: [366, 133, 429, 162]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '2', ',', '4', ' ', 'k', 'g']\n",
      "    cell_id: 22\n",
      "    type: content\n",
      "    bbox: [476, 133, 548, 162]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '2', ',', '9', '8', ' ', 'k', 'g']\n",
      "    cell_id: 23\n",
      "    type: content\n",
      "    bbox: [582, 133, 662, 162]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['C', 'á', 'i']\n",
      "    cell_id: 24\n",
      "    type: content\n",
      "    bbox: [57, 172, 93, 201]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['5', ',', '3', ' ', 'k', 'g']\n",
      "    cell_id: 25\n",
      "    type: content\n",
      "    bbox: [150, 172, 213, 201]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '0', ',', '1', ' ', 'k', 'g']\n",
      "    cell_id: 26\n",
      "    type: content\n",
      "    bbox: [247, 172, 319, 201]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['9', ',', '1', ' ', 'k', 'g']\n",
      "    cell_id: 27\n",
      "    type: content\n",
      "    bbox: [366, 172, 429, 201]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '1', ',', '7', ' ', 'k', 'g']\n",
      "    cell_id: 28\n",
      "    type: content\n",
      "    bbox: [476, 172, 548, 201]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '0', ',', '7', ' ', 'k', 'g']\n",
      "    cell_id: 29\n",
      "    type: content\n",
      "    bbox: [587, 172, 659, 201]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['6', ' ', 't', 'h', 'á', 'n', 'g', ':', ' ', 'Đ', 'ự', 'c']\n",
      "    cell_id: 30\n",
      "    type: content\n",
      "    bbox: [17, 211, 133, 240]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['9', ',', '7', ' ', 'k', 'g']\n",
      "    cell_id: 31\n",
      "    type: content\n",
      "    bbox: [150, 211, 213, 240]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '7', ',', '9', ' ', 'k', 'g']\n",
      "    cell_id: 32\n",
      "    type: content\n",
      "    bbox: [247, 211, 319, 240]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '4', ',', '8', '7', ' ', 'k', 'g']\n",
      "    cell_id: 33\n",
      "    type: content\n",
      "    bbox: [357, 211, 437, 240]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '8', ',', '6', ' ', 'k', 'g']\n",
      "    cell_id: 34\n",
      "    type: content\n",
      "    bbox: [476, 211, 548, 240]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '9', ' ', 'k', 'g']\n",
      "    cell_id: 35\n",
      "    type: content\n",
      "    bbox: [596, 211, 650, 240]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['C', 'á', 'i']\n",
      "    cell_id: 36\n",
      "    type: content\n",
      "    bbox: [57, 250, 93, 279]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['8', ',', '2', ' ', 'k', 'g']\n",
      "    cell_id: 37\n",
      "    type: content\n",
      "    bbox: [150, 250, 213, 279]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '5', ',', '9', ' ', 'k', 'g']\n",
      "    cell_id: 38\n",
      "    type: content\n",
      "    bbox: [247, 250, 319, 279]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '2', ',', '5', ' ', 'k', 'g']\n",
      "    cell_id: 39\n",
      "    type: content\n",
      "    bbox: [362, 250, 434, 279]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '4', ',', '6', ' ', 'k', 'g']\n",
      "    cell_id: 40\n",
      "    type: content\n",
      "    bbox: [476, 250, 548, 279]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '5', ',', '4', ' ', 'k', 'g']\n",
      "    cell_id: 41\n",
      "    type: content\n",
      "    bbox: [587, 250, 659, 279]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['9', ' ', 't', 'h', 'á', 'n', 'g', ':', ' ', 'Đ', 'ự', 'c']\n",
      "    cell_id: 42\n",
      "    type: content\n",
      "    bbox: [17, 289, 133, 318]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '4', ',', '3', ' ', 'k', 'g']\n",
      "    cell_id: 43\n",
      "    type: content\n",
      "    bbox: [145, 289, 217, 318]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '5', ',', '5', ' ', 'k', 'g']\n",
      "    cell_id: 44\n",
      "    type: content\n",
      "    bbox: [247, 289, 319, 318]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '9', ',', '4', ' ', 'k', 'g']\n",
      "    cell_id: 45\n",
      "    type: content\n",
      "    bbox: [362, 289, 434, 318]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '4', ',', '0', ' ', 'k', 'g']\n",
      "    cell_id: 46\n",
      "    type: content\n",
      "    bbox: [476, 289, 548, 318]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '6', ',', '6', ' ', 'k', 'g']\n",
      "    cell_id: 47\n",
      "    type: content\n",
      "    bbox: [587, 289, 659, 318]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['C', 'á', 'i']\n",
      "    cell_id: 48\n",
      "    type: content\n",
      "    bbox: [57, 328, 93, 357]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '3', ',', '7', ' ', 'k', 'g']\n",
      "    cell_id: 49\n",
      "    type: content\n",
      "    bbox: [145, 328, 217, 357]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '2', ',', '1', ' ', 'k', 'g']\n",
      "    cell_id: 50\n",
      "    type: content\n",
      "    bbox: [247, 328, 319, 357]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '5', ',', '3', ' ', 'k', 'g']\n",
      "    cell_id: 51\n",
      "    type: content\n",
      "    bbox: [362, 328, 434, 357]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '0', ',', '6', ' ', 'k', 'g']\n",
      "    cell_id: 52\n",
      "    type: content\n",
      "    bbox: [476, 328, 548, 357]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '2', ',', '9', ' ', 'k', 'g']\n",
      "    cell_id: 53\n",
      "    type: content\n",
      "    bbox: [587, 328, 659, 357]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '2', ' ', 't', 'h', 'á', 'n', 'g', ':', ' ', 'Đ', 'ự', 'c']\n",
      "    cell_id: 54\n",
      "    type: content\n",
      "    bbox: [13, 367, 137, 396]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '9', ',', '8', ' ', 'k', 'g']\n",
      "    cell_id: 55\n",
      "    type: content\n",
      "    bbox: [145, 367, 217, 396]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', '1', ',', '4', ' ', 'k', 'g']\n",
      "    cell_id: 56\n",
      "    type: content\n",
      "    bbox: [247, 367, 319, 396]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '3', ',', '3', ' ', 'k', 'g']\n",
      "    cell_id: 57\n",
      "    type: content\n",
      "    bbox: [362, 367, 434, 396]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', '0', ',', '2', ' ', 'k', 'g']\n",
      "    cell_id: 58\n",
      "    type: content\n",
      "    bbox: [476, 367, 548, 396]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', '1', ',', '6', ' ', 'k', 'g']\n",
      "    cell_id: 59\n",
      "    type: content\n",
      "    bbox: [587, 367, 659, 396]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['C', 'á', 'i']\n",
      "    cell_id: 60\n",
      "    type: content\n",
      "    bbox: [57, 406, 93, 435]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '7', ',', '2', ' ', 'k', 'g']\n",
      "    cell_id: 61\n",
      "    type: content\n",
      "    bbox: [145, 406, 217, 435]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '6', ',', '8', '1', ' ', 'k', 'g']\n",
      "    cell_id: 62\n",
      "    type: content\n",
      "    bbox: [243, 406, 323, 435]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '8', ',', '3', '1', ' ', 'k', 'g']\n",
      "    cell_id: 63\n",
      "    type: content\n",
      "    bbox: [357, 406, 437, 435]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '9', ',', '4', ' ', 'k', 'g']\n",
      "    cell_id: 64\n",
      "    type: content\n",
      "    bbox: [476, 406, 548, 435]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '5', ',', '7', ' ', 'k', 'g']\n",
      "    cell_id: 65\n",
      "    type: content\n",
      "    bbox: [587, 406, 659, 435]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['1', '8', ' ', 't', 'h', 'á', 'n', 'g', ':', ' ', 'Đ', 'ự', 'c']\n",
      "    cell_id: 66\n",
      "    type: content\n",
      "    bbox: [13, 445, 137, 474]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '5', ',', '0', ' ', 'k', 'g']\n",
      "    cell_id: 67\n",
      "    type: content\n",
      "    bbox: [145, 445, 217, 474]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['4', '1', ',', '7', ' ', 'k', 'g']\n",
      "    cell_id: 68\n",
      "    type: content\n",
      "    bbox: [247, 445, 319, 474]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', '1', ',', '1', ' ', 'k', 'g']\n",
      "    cell_id: 69\n",
      "    type: content\n",
      "    bbox: [362, 445, 434, 474]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', '9', ',', '3', ' ', 'k', 'g']\n",
      "    cell_id: 70\n",
      "    type: content\n",
      "    bbox: [476, 445, 548, 474]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['4', '0', ',', '9', ' ', 'k', 'g']\n",
      "    cell_id: 71\n",
      "    type: content\n",
      "    bbox: [587, 445, 659, 474]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['C', 'á', 'i']\n",
      "    cell_id: 72\n",
      "    type: content\n",
      "    bbox: [57, 484, 93, 513]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '0', ',', '7', ' ', 'k', 'g']\n",
      "    cell_id: 73\n",
      "    type: content\n",
      "    bbox: [145, 484, 217, 513]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', '3', ',', '5', ' ', 'k', 'g']\n",
      "    cell_id: 74\n",
      "    type: content\n",
      "    bbox: [247, 484, 319, 513]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '1', ',', '8', ' ', 'k', 'g']\n",
      "    cell_id: 75\n",
      "    type: content\n",
      "    bbox: [362, 484, 434, 513]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '7', ',', '1', ' ', 'k', 'g']\n",
      "    cell_id: 76\n",
      "    type: content\n",
      "    bbox: [476, 484, 548, 513]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '9', ',', '6', ' ', 'k', 'g']\n",
      "    cell_id: 77\n",
      "    type: content\n",
      "    bbox: [587, 484, 659, 513]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '4', ' ', 't', 'h', 'á', 'n', 'g', ':', ' ', 'Đ', 'ự', 'c']\n",
      "    cell_id: 78\n",
      "    type: content\n",
      "    bbox: [13, 523, 137, 552]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '8', ',', '0', ' ', 'k', 'g']\n",
      "    cell_id: 79\n",
      "    type: content\n",
      "    bbox: [145, 523, 217, 552]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['4', '6', ',', '2', ' ', 'k', 'g']\n",
      "    cell_id: 80\n",
      "    type: content\n",
      "    bbox: [247, 523, 319, 552]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', '4', ',', '7', ' ', 'k', 'g']\n",
      "    cell_id: 81\n",
      "    type: content\n",
      "    bbox: [362, 523, 434, 552]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['4', '7', ',', '5', ' ', 'k', 'g']\n",
      "    cell_id: 82\n",
      "    type: content\n",
      "    bbox: [476, 523, 548, 552]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['5', '0', ' ', 'k', 'g']\n",
      "    cell_id: 83\n",
      "    type: content\n",
      "    bbox: [596, 523, 650, 552]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['C', 'á', 'i']\n",
      "    cell_id: 84\n",
      "    type: content\n",
      "    bbox: [57, 562, 93, 591]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '2', ',', '8', ' ', 'k', 'g']\n",
      "    cell_id: 85\n",
      "    type: content\n",
      "    bbox: [145, 562, 217, 591]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', '5', ',', '3', ' ', 'k', 'g']\n",
      "    cell_id: 86\n",
      "    type: content\n",
      "    bbox: [247, 562, 319, 591]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '3', ',', '7', '1', ' ', 'k', 'g']\n",
      "    cell_id: 87\n",
      "    type: content\n",
      "    bbox: [357, 562, 437, 591]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '9', ',', '0', ' ', 'k', 'g']\n",
      "    cell_id: 88\n",
      "    type: content\n",
      "    bbox: [476, 562, 548, 591]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', '3', ',', '0', ' ', 'k', 'g']\n",
      "    cell_id: 89\n",
      "    type: content\n",
      "    bbox: [587, 562, 659, 591]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', '0', ' ', 't', 'h', 'á', 'n', 'g', ':', ' ', 'Đ', 'ự', 'c']\n",
      "    cell_id: 90\n",
      "    type: content\n",
      "    bbox: [13, 601, 137, 630]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', '2', ',', '8', ' ', 'k', 'g']\n",
      "    cell_id: 91\n",
      "    type: content\n",
      "    bbox: [145, 601, 217, 630]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['5', '4', ',', '3', ' ', 'k', 'g']\n",
      "    cell_id: 92\n",
      "    type: content\n",
      "    bbox: [247, 601, 319, 630]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', '9', ',', '7', ' ', 'k', 'g']\n",
      "    cell_id: 93\n",
      "    type: content\n",
      "    bbox: [362, 601, 434, 630]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['5', '4', ',', '4', ' ', 'k', 'g']\n",
      "    cell_id: 94\n",
      "    type: content\n",
      "    bbox: [476, 601, 548, 630]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['5', '6', ',', '2', ' ', 'k', 'g']\n",
      "    cell_id: 95\n",
      "    type: content\n",
      "    bbox: [587, 601, 659, 630]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['C', 'á', 'i']\n",
      "    cell_id: 96\n",
      "    type: content\n",
      "    bbox: [57, 640, 93, 669]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '5', ',', '7', ' ', 'k', 'g']\n",
      "    cell_id: 97\n",
      "    type: content\n",
      "    bbox: [145, 640, 217, 669]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', '8', ',', '6', ' ', 'k', 'g']\n",
      "    cell_id: 98\n",
      "    type: content\n",
      "    bbox: [247, 640, 319, 669]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '5', ',', '8', ' ', 'k', 'g']\n",
      "    cell_id: 99\n",
      "    type: content\n",
      "    bbox: [362, 640, 434, 669]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', '2', ',', '1', ' ', 'k', 'g']\n",
      "    cell_id: 100\n",
      "    type: content\n",
      "    bbox: [476, 640, 548, 669]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', '6', ',', '0', ' ', 'k', 'g']\n",
      "    cell_id: 101\n",
      "    type: content\n",
      "    bbox: [587, 640, 659, 669]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', '6', ' ', 't', 'h', 'á', 'n', 'g', ':', ' ', 'Đ', 'ự', 'c']\n",
      "    cell_id: 102\n",
      "    type: content\n",
      "    bbox: [13, 679, 137, 708]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', '6', ',', '6', ' ', 'k', 'g']\n",
      "    cell_id: 103\n",
      "    type: content\n",
      "    bbox: [145, 679, 217, 708]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['5', '7', ',', '3', ' ', 'k', 'g']\n",
      "    cell_id: 104\n",
      "    type: content\n",
      "    bbox: [247, 679, 319, 708]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['4', '4', ',', '9', ' ', 'k', 'g']\n",
      "    cell_id: 105\n",
      "    type: content\n",
      "    bbox: [362, 679, 434, 708]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['5', '9', ',', '5', ' ', 'k', 'g']\n",
      "    cell_id: 106\n",
      "    type: content\n",
      "    bbox: [476, 679, 548, 708]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['6', '2', ',', '3', ' ', 'k', 'g']\n",
      "    cell_id: 107\n",
      "    type: content\n",
      "    bbox: [587, 679, 659, 708]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['C', 'á', 'i']\n",
      "    cell_id: 108\n",
      "    type: content\n",
      "    bbox: [57, 718, 93, 747]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '7', ',', '6', ' ', 'k', 'g']\n",
      "    cell_id: 109\n",
      "    type: content\n",
      "    bbox: [145, 718, 217, 747]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['4', '0', ',', '6', ' ', 'k', 'g']\n",
      "    cell_id: 110\n",
      "    type: content\n",
      "    bbox: [247, 718, 319, 747]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '8', ',', '0', ' ', 'k', 'g']\n",
      "    cell_id: 111\n",
      "    type: content\n",
      "    bbox: [362, 718, 434, 747]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['3', '6', ',', '2', ' ', 'k', 'g']\n",
      "    cell_id: 112\n",
      "    type: content\n",
      "    bbox: [476, 718, 548, 747]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['4', '0', ',', '1', ' ', 'k', 'g']\n",
      "    cell_id: 113\n",
      "    type: content\n",
      "    bbox: [587, 718, 659, 747]\n",
      "  }\n",
      "  ]\n",
      "  img_info: \n",
      "  {\n",
      "    height: None\n",
      "    width: None\n",
      "    split: train\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def print_dict(d, indent=2):\n",
    "    \"\"\"Prints a dictionary in a readable format.\"\"\"\n",
    "    print(' ' * (indent - 2) + '{')\n",
    "    for key, value in d.items():\n",
    "        print(' ' * indent + f\"{key}: \", end='')\n",
    "        if isinstance(value, dict):\n",
    "            print()\n",
    "            print_dict(value, indent + 2)\n",
    "        elif isinstance(value, list):\n",
    "            if value and all(isinstance(item, dict) for item in value):\n",
    "                print('[')\n",
    "                for item in value:\n",
    "                    print_dict(item, indent + 2)\n",
    "                print(' ' * indent + ']')\n",
    "            else:\n",
    "                print(value)\n",
    "        else:\n",
    "            print(value)\n",
    "    print(' ' * (indent - 2) + '}')\n",
    "\n",
    "import random\n",
    "print_dict(dataset[random.randint(0, len(dataset) - 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ee6fe86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Original Sample ===\n",
      "{\n",
      "  img_path: F:/data/vitabset/train\\143609.png\n",
      "  sample_idx: 80\n",
      "  instances: [\n",
      "  {\n",
      "    tokens: ['<thead>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '</thead>', '<tbody>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '<tr>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '<td>', '</td>', '</tr>', '</tbody>']\n",
      "    type: structure\n",
      "  }\n",
      "  {\n",
      "    tokens: ['N', 'ă', 'm']\n",
      "    cell_id: 0\n",
      "    type: content\n",
      "    bbox: [9, 13, 52, 40]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['T', 'ê', 'n', ' ', 'p', 'h', 'i', 'm']\n",
      "    cell_id: 1\n",
      "    type: content\n",
      "    bbox: [224, 13, 300, 40]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['V', 'a', 'i']\n",
      "    cell_id: 2\n",
      "    type: content\n",
      "    bbox: [514, 13, 547, 40]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['C', 'h', 'ú', ' ', 't', 'h', 'í', 'c', 'h']\n",
      "    cell_id: 3\n",
      "    type: content\n",
      "    bbox: [649, 13, 727, 40]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '0', '1', '2']\n",
      "    cell_id: 4\n",
      "    type: content\n",
      "    bbox: [9, 49, 51, 76]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['<i>', 'I', ' ', 'A', 'M', '.', ' ', '-', ' ', 'S', 'M', ' ', 'T', 'o', 'w', 'n', ' ', 'L', 'i', 'v', 'e', ' ', 'W', 'o', 'r', 'l', 'd', ' ', 'T', 'o', 'u', 'r', ' ', 'i', 'n', ' ', 'M', 'a', 'd', 'i', 's', 'o', 'n', ' ', 'S', 'q', 'u', 'a', 'r', 'e', ' ', 'G', 'a', 'r', 'd', 'e', 'n', '</i>']\n",
      "    cell_id: 5\n",
      "    type: content\n",
      "    bbox: [60, 49, 464, 76]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['C', 'h', 'í', 'n', 'h', ' ', 'm', 'ì', 'n', 'h']\n",
      "    cell_id: 6\n",
      "    type: content\n",
      "    bbox: [472, 49, 558, 76]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['P', 'h', 'i', 'm', ' ', 't', 'i', 'ể', 'u', ' ', 's', 'ử', ' ', 'c', 'ủ', 'a', ' ', 'S', 'M', ' ', 'T', 'o', 'w', 'n']\n",
      "    cell_id: 7\n",
      "    type: content\n",
      "    bbox: [596, 49, 780, 76]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '0', '1', '6']\n",
      "    cell_id: 8\n",
      "    type: content\n",
      "    bbox: [9, 85, 51, 112]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['<i>', 'I', ' ', 'L', 'o', 'v', 'e', ' ', 'T', 'h', 'a', 't', ' ', 'C', 'r', 'a', 'z', 'y', ' ', 'L', 'i', 't', 't', 'l', 'e', ' ', 'T', 'h', 'i', 'n', 'g', '</i>']\n",
      "    cell_id: 9\n",
      "    type: content\n",
      "    bbox: [60, 85, 265, 112]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['L', 'ạ', 'c', ' ', 'T', 'h', 'i', 'ế', 'n', ' ', 'T', 'h', 'i', 'ế', 'n']\n",
      "    cell_id: 10\n",
      "    type: content\n",
      "    bbox: [472, 85, 588, 112]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['2', '0', '1', '6']\n",
      "    cell_id: 12\n",
      "    type: content\n",
      "    bbox: [9, 121, 51, 148]\n",
      "  }\n",
      "  {\n",
      "    tokens: ['<i>', 'M', 'y', ' ', 'O', 't', 'h', 'e', 'r', ' ', 'H', 'o', 'm', 'e', '</i>']\n",
      "    cell_id: 13\n",
      "    type: content\n",
      "    bbox: [60, 121, 174, 148]\n",
      "  }\n",
      "  ]\n",
      "  img_info: \n",
      "  {\n",
      "    height: None\n",
      "    width: None\n",
      "    split: train\n",
      "  }\n",
      "}\n",
      "\n",
      "=== Step 1: LoadImageFromFile ===\n",
      "Transform: LoadImageFromFile(ignore_empty=False, min_size=0, to_float32=False, color_type='color', imdecode_backend='cv2', backend_args=None)\n",
      "Before: ['img_path', 'sample_idx', 'instances', 'img_info']\n",
      "After: ['img_path', 'sample_idx', 'instances', 'img_info', 'img', 'img_shape', 'ori_shape']\n",
      "{\n",
      "  img: [[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n",
      "  img_shape: (161, 791)\n",
      "  ori_shape: (161, 791)\n",
      "}\n",
      "\n",
      "=== Step 2: LoadTokens ===\n",
      "Transform: LoadTokens(with_structure=True, with_cell=False, max_structure_token_len=600, max_cell_token_len=None)\n",
      "Before: ['img_path', 'sample_idx', 'instances', 'img_info', 'img', 'img_shape', 'ori_shape']\n",
      "After: ['img_path', 'sample_idx', 'instances', 'img_info', 'img', 'img_shape', 'ori_shape', 'tokens', 'bboxes', 'masks']\n",
      "{\n",
      "  tokens: ['<thead>', '<tr>', '<td></td>', '<td></td>', '<td></td>', '<td></td>', '</tr>', '</thead>', '<tbody>', '<tr>', '<td></td>', '<td></td>', '<td></td>', '<td></td>', '</tr>', '<tr>', '<td></td>', '<td></td>', '<td></td>', '<td></td>', '</tr>', '<tr>', '<td></td>', '<td></td>', '<td></td>', '<td></td>', '</tr>', '</tbody>']\n",
      "  bboxes: [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [9, 13, 52, 40], [224, 13, 300, 40], [514, 13, 547, 40], [649, 13, 727, 40], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [9, 49, 51, 76], [60, 49, 464, 76], [472, 49, 558, 76], [596, 49, 780, 76], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [9, 85, 51, 112], [60, 85, 265, 112], [472, 85, 588, 112], [0, 0, 0, 0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [9, 121, 51, 148], [60, 121, 174, 148], [0, 0, 0, 0], [0, 0, 0, 0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0]]\n",
      "  masks: [0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0]\n",
      "}\n",
      "\n",
      "=== Step 3: TableResize ===\n",
      "Transform: TableResize(min_size=None, long_size=480)\n",
      "Before: ['img_path', 'sample_idx', 'instances', 'img_info', 'img', 'img_shape', 'ori_shape', 'tokens', 'bboxes', 'masks']\n",
      "After: ['img_path', 'sample_idx', 'instances', 'img_info', 'img', 'img_shape', 'ori_shape', 'tokens', 'bboxes', 'masks', 'scale', 'scale_factor', 'keep_ratio']\n",
      "{\n",
      "  img: [[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n",
      "  img_shape: (97, 477)\n",
      "  scale: (480, 97)\n",
      "  scale_factor: (0.6030341340075853, 0.6024844720496895)\n",
      "  keep_ratio: True\n",
      "}\n",
      "\n",
      "=== Step 4: TablePad ===\n",
      "Transform: TablePad(size=(480, 480), size_divisor=None, pad_val={'img': 0, 'seg': 255}, pad_to_square=False, padding_mode='constant', return_mask=False, mask_ratio=1)\n",
      "Before: ['img_path', 'sample_idx', 'instances', 'img_info', 'img', 'img_shape', 'ori_shape', 'tokens', 'bboxes', 'masks', 'scale', 'scale_factor', 'keep_ratio']\n",
      "After: ['img_path', 'sample_idx', 'instances', 'img_info', 'img', 'img_shape', 'ori_shape', 'tokens', 'bboxes', 'masks', 'scale', 'scale_factor', 'keep_ratio', 'pad_shape', 'pad_fixed_size', 'pad_size_divisor']\n",
      "{\n",
      "  img: [[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]]\n",
      "  img_shape: (480, 480)\n",
      "  pad_shape: (480, 480, 3)\n",
      "  pad_fixed_size: (480, 480)\n",
      "  pad_size_divisor: None\n",
      "}\n",
      "\n",
      "=== Step 5: PackInputs ===\n",
      "Transform: PackInputs(keys=['img'], meta_keys=('filename', 'ori_shape', 'img_shape', 'scale_factor', 'img_norm_cfg', 'ori_filename', 'pad_shape', 'valid_ratio'), mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      "Before: ['img_path', 'sample_idx', 'instances', 'img_info', 'img', 'img_shape', 'ori_shape', 'tokens', 'bboxes', 'masks', 'scale', 'scale_factor', 'keep_ratio', 'pad_shape', 'pad_fixed_size', 'pad_size_divisor']\n",
      "After: ['img_norm_cfg', 'inputs', 'data_samples']\n",
      "{\n",
      "  img_norm_cfg: \n",
      "  {\n",
      "    mean: [0.5, 0.5, 0.5]\n",
      "    std: [0.5, 0.5, 0.5]\n",
      "  }\n",
      "  inputs: tensor([[[509., 509., 509.,  ...,  -1.,  -1.,  -1.],\n",
      "         [509., 509., 509.,  ...,  -1.,  -1.,  -1.],\n",
      "         [509., 509., 509.,  ...,  -1.,  -1.,  -1.],\n",
      "         ...,\n",
      "         [ -1.,  -1.,  -1.,  ...,  -1.,  -1.,  -1.],\n",
      "         [ -1.,  -1.,  -1.,  ...,  -1.,  -1.,  -1.],\n",
      "         [ -1.,  -1.,  -1.,  ...,  -1.,  -1.,  -1.]],\n",
      "\n",
      "        [[509., 509., 509.,  ...,  -1.,  -1.,  -1.],\n",
      "         [509., 509., 509.,  ...,  -1.,  -1.,  -1.],\n",
      "         [509., 509., 509.,  ...,  -1.,  -1.,  -1.],\n",
      "         ...,\n",
      "         [ -1.,  -1.,  -1.,  ...,  -1.,  -1.,  -1.],\n",
      "         [ -1.,  -1.,  -1.,  ...,  -1.,  -1.,  -1.],\n",
      "         [ -1.,  -1.,  -1.,  ...,  -1.,  -1.,  -1.]],\n",
      "\n",
      "        [[509., 509., 509.,  ...,  -1.,  -1.,  -1.],\n",
      "         [509., 509., 509.,  ...,  -1.,  -1.,  -1.],\n",
      "         [509., 509., 509.,  ...,  -1.,  -1.,  -1.],\n",
      "         ...,\n",
      "         [ -1.,  -1.,  -1.,  ...,  -1.,  -1.,  -1.],\n",
      "         [ -1.,  -1.,  -1.,  ...,  -1.,  -1.,  -1.],\n",
      "         [ -1.,  -1.,  -1.,  ...,  -1.,  -1.,  -1.]]])\n",
      "  data_samples: <TokenRecogDataSample(\n",
      "\n",
      "    META INFORMATION\n",
      "    filename: None\n",
      "    ori_shape: (161, 791)\n",
      "    pad_shape: (480, 480, 3)\n",
      "    img_shape: (480, 480)\n",
      "    img_norm_cfg: None\n",
      "    ori_filename: None\n",
      "    scale_factor: (0.6030341340075853, 0.6024844720496895)\n",
      "    valid_ratio: 1\n",
      "\n",
      "    DATA FIELDS\n",
      "    gt_tokens: <LabelData(\n",
      "        \n",
      "            META INFORMATION\n",
      "        \n",
      "            DATA FIELDS\n",
      "            item: ['<thead>', '<tr>', '<td></td>', '<td></td>', '<td></td>', '<td></td>', '</tr>', '</thead>', '<tbody>', '<tr>', '<td></td>', '<td></td>', '<td></td>', '<td></td>', '</tr>', '<tr>', '<td></td>', '<td></td>', '<td></td>', '<td></td>', '</tr>', '<tr>', '<td></td>', '<td></td>', '<td></td>', '<td></td>', '</tr>', '</tbody>']\n",
      "        ) at 0x1c0e97355d0>\n",
      "    gt_bboxes: <LabelData(\n",
      "        \n",
      "            META INFORMATION\n",
      "        \n",
      "            DATA FIELDS\n",
      "            item: [[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [9, 13, 52, 40], [224, 13, 300, 40], [514, 13, 547, 40], [649, 13, 727, 40], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [9, 49, 51, 76], [60, 49, 464, 76], [472, 49, 558, 76], [596, 49, 780, 76], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [9, 85, 51, 112], [60, 85, 265, 112], [472, 85, 588, 112], [0, 0, 0, 0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [9, 121, 51, 148], [60, 121, 174, 148], [0, 0, 0, 0], [0, 0, 0, 0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0]]\n",
      "        ) at 0x1c0e9735550>\n",
      ") at 0x1c0e4fd6350>\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def is_equal(a, b):\n",
    "    if isinstance(a, (np.ndarray, torch.Tensor)) and isinstance(b, (np.ndarray, torch.Tensor)):\n",
    "        if isinstance(a, torch.Tensor):\n",
    "            return torch.equal(a, b)\n",
    "        return np.array_equal(a, b)\n",
    "    return a == b\n",
    "\n",
    "# sample = dataset[random.randint(0, len(dataset) - 1)].copy()\n",
    "sample = dataset[80].copy()\n",
    "\n",
    "print(\"\\n=== Original Sample ===\")\n",
    "print_dict(sample)\n",
    "\n",
    "for i, transform in enumerate(pipeline.transforms):\n",
    "    print(f\"\\n=== Step {i+1}: {transform.__class__.__name__} ===\")\n",
    "    print(f\"Transform: {transform}\")\n",
    "    print(f\"Before: {list(sample.keys())}\")\n",
    "    \n",
    "    old_sample = sample.copy()\n",
    "    sample = transform(sample)\n",
    "    \n",
    "    print(f\"After: {list(sample.keys())}\")\n",
    "    diff = {k: v for k, v in sample.items() if k not in old_sample or not is_equal(old_sample[k], v)}\n",
    "    print_dict(diff, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b43381a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[80].copy()\n",
    "idx = [s.get('cell_id') for s in sample['instances'] if s.get('type') == 'content']\n",
    "print(f\"Cell IDs: {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fc7fe29",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'img_norm_cfg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m     plt.axis(\u001b[33m'\u001b[39m\u001b[33moff\u001b[39m\u001b[33m'\u001b[39m) \n\u001b[32m     25\u001b[39m     plt.show()\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m mean = \u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimg_norm_cfg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     28\u001b[39m std = sample[\u001b[33m'\u001b[39m\u001b[33mimg_norm_cfg\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mstd\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     29\u001b[39m img, instances = sample[\u001b[33m'\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m'\u001b[39m], sample[\u001b[33m'\u001b[39m\u001b[33mdata_samples\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mKeyError\u001b[39m: 'img_norm_cfg'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_normalized_img(img, mean, std):\n",
    "    \"\"\"Hiển thị ảnh đã normalize\"\"\"\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        img = img.cpu().numpy()\n",
    "    \n",
    "    if len(img.shape) == 4:\n",
    "        img = img[0]\n",
    "    \n",
    "    # Denormalize: (img * std) + mean\n",
    "    # Reshape mean và std để match với image shape (C,H,W)\n",
    "    mean = np.array(mean).reshape(3, 1, 1)\n",
    "    std = np.array(std).reshape(3, 1, 1)\n",
    "    denorm = (img * std) + mean\n",
    "    denorm = (denorm - denorm.min()) / (denorm.max() - denorm.min()) # Chuẩn hóa lại về khoảng [0, 1]\n",
    "    \n",
    "    # Chuyển từ (C,H,W) sang (H,W,C) để hiển thị\n",
    "    denorm = np.transpose(denorm, (1, 2, 0))\n",
    "    \n",
    "    plt.imshow(denorm)\n",
    "    plt.axis('off') \n",
    "    plt.show()\n",
    "\n",
    "mean = sample['img_norm_cfg']['mean']\n",
    "std = sample['img_norm_cfg']['std']\n",
    "img, instances = sample['inputs'], sample['data_samples']\n",
    "show_normalized_img(img, mean, std)\n",
    "print(instances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
